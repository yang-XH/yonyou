{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# author: 卢克治\n",
    "# 完成对文本中所有满足条件的结果进行全部替换\n",
    "def clean_replace_all(content,find_str,replace_str):\n",
    "    while content.find(find_str) > 0:\n",
    "        content = content.replace(find_str, replace_str)\n",
    "    return content\n",
    "\n",
    "\n",
    "# Author：卢克治\n",
    "# Function：完成对content内容中的html格式重新清洗，添加上标点符号\n",
    "def clean_content_addPunctuation(content):\n",
    "    #lucas 整理需要直接替换为空的标识符集合\n",
    "    sub_to_space_list = [\"<b>\",\"&nbsp;\",\"<u>\",\"<span>\",\"<strong>\",\"<label>\",\"<span lang=EN-US>\",\"\\u3000\",\"<p></p>\",\"</span>\",\"</font>\",\"</FONT>\",\"*\"]\n",
    "    #lucas 整理需要直接替换为句号-\"。\"的标识符集合\n",
    "    sub_to_fullStop_list = [\"</b>\",\"</u>\",\"</label>\", \"</a>\",\"<br>\",\"</br>\",\"</div>\",\"</title>\"]\n",
    "    #lucas 整理需要直接替换为分号-\"；\"的标识符集合\n",
    "    sub_to_semicolon_list = []\n",
    "    # lucas 整理需要直接替换为逗号-\"，\"的标识符集合\n",
    "    sub_to_comma_list = [\"</p>\",\"</strong>\"]\n",
    "\n",
    "    #lucas 按照以上符号类别进行替换\n",
    "    for sub_item in sub_to_space_list:\n",
    "        content = content.replace(sub_item, \"\")\n",
    "    for sub_item in sub_to_fullStop_list:\n",
    "        content = content.replace(sub_item, \"。\")\n",
    "    for sub_item in sub_to_semicolon_list:\n",
    "        content = content.replace(sub_item, \"；\")\n",
    "    for sub_item in sub_to_comma_list:\n",
    "        content = content.replace(sub_item, \"，\")\n",
    "\n",
    "    # 去除标签<u>、空格、&nbsp;、特定标签\n",
    "    content = re.sub(r'\\<span.*?\\>', \"\", content)\n",
    "    content = re.sub(r'\\<font.*?\\>', \"\", content)\n",
    "    content = re.sub(r'\\<FONT.*?\\>', \"\", content)\n",
    "    content = re.sub(r'\\<a.*?\\>', \"\", content)\n",
    "\n",
    "\n",
    "    # content = content.encode('gbk', 'ignore').decode('gbk', 'ignore').encode('utf8', 'ignore').decode('utf8',\n",
    "    #                                                                                                   'ignore')  # 去除一些特殊的符号\n",
    "\n",
    "    ss = re.sub('<[^>]+>', '#', content) # 去除<>包含的内容\n",
    "    clean_content = ss.split(\"#\")\n",
    "    clean_content = [i.replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\t\", \" \") for i in clean_content]  # 去除换行和tab\n",
    "    clean_content = [re.sub(r'[@a-zA-Z0-9-\\.：; \\t]{3,}\\{.*?\\}', '', i) for i in clean_content]  # 去除CSS格式\n",
    "    clean_content = [i.strip() for i in clean_content]\n",
    "    clean_content = [i.replace(\" \", \"\") for i in clean_content if i != \"\"]\n",
    "    clean_content = [i for i in clean_content if i != \"\"]\n",
    "    clean_content = [i.replace(\":\", \"：\") for i in clean_content]\n",
    "    clean_content = [i.replace(\"？\", \"\") for i in clean_content]\n",
    "\n",
    "\n",
    "    #lucas 添加最终输出文本格式的过滤\n",
    "    clean_content_result = \"\".join(clean_content)\n",
    "    clean_content_result = clean_replace_all(clean_content_result,\" \", \"\")  # lucas 直接将空格全部删除\n",
    "    clean_content_result = clean_replace_all(clean_content_result,\"：，\", \"：\")    # lucas 将：，符号删除逗号。\n",
    "    clean_content_result = clean_replace_all(clean_content_result, \"，：\", \"：\")   # lucas 将，：符号删除逗号。\n",
    "    clean_content_result = clean_replace_all(clean_content_result,\"。。\", \"。\")\n",
    "    clean_content_result = clean_replace_all(clean_content_result,\"，，\", \"，\")\n",
    "    clean_content_result = clean_replace_all(clean_content_result,\"：。\", \"：\")    # lucas 将：。符号删除句号。\n",
    "    clean_content_result = clean_replace_all(clean_content_result, \"。：\", \"：\")\n",
    "    clean_content_result = clean_replace_all(clean_content_result,\"。，\", \"。\")\n",
    "    clean_content_result = clean_replace_all(clean_content_result,\"，。\", \"。\")\n",
    "    clean_content_result = clean_replace_all(clean_content_result,\",\", \"，\")\n",
    "\n",
    "    return [clean_content_result]\n",
    "\n",
    "\n",
    "# lucas\n",
    "# 清洗html格式主函数\n",
    "def clean_html_format(input_file,output_file):\n",
    "    result_wrong_pd = pd.read_csv(input_file,\n",
    "                                  names=['0', 'id', \"2\", \"3\", \"4\", \"5\", \"6\", \"content\", \"8\", \"9\", \"10\", \"11\", \"12\"],\n",
    "                                  usecols=[\"id\", \"content\"], encoding=\"gb18030\")\n",
    "    result_clean = [clean_content(str(c)) for c in result_wrong_pd[\"content\"]]\n",
    "    result_clean_lucas = [clean_content_addPunctuation(str(c)) for c in result_wrong_pd[\"content\"]]\n",
    "    for i, line in enumerate(result_clean):\n",
    "        temp = \"\"\n",
    "        for elem in line:\n",
    "            temp += elem\n",
    "            temp += \" \"\n",
    "        result_clean[i] = temp\n",
    "    for i, line in enumerate(result_clean_lucas):\n",
    "        temp = \"\"\n",
    "        for elem in line:\n",
    "            temp += elem\n",
    "            temp += \" \"\n",
    "        result_clean_lucas[i] = temp\n",
    "    # lucas将id信息和清洗后的数据进行拼接\n",
    "    result_id = result_wrong_pd[\"id\"]\n",
    "    result_filter_content = pd.DataFrame(result_clean, columns=[\"filter_content\"])\n",
    "    result_filter_content_lucas = pd.DataFrame(result_clean_lucas, columns=[\"filter_content_lucas\"])\n",
    "    filter_result = pd.concat(\n",
    "        [result_id, result_wrong_pd[\"content\"], result_filter_content, result_filter_content_lucas], axis=1)\n",
    "    filter_result.to_csv(output_file, index=None)\n",
    "    del filter_result #lucas 释放变量占用的内存\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "# lucas\n",
    "# 读取处理完html并加上标点符号的csv文件，将其中第四列-含标点的结果进行汇总\n",
    "def huizong_html_format(input_file,output_file):\n",
    "    result_wrong_pd = pd.read_csv(input_file,\n",
    "                                  header=0,\n",
    "                                  usecols=[\"id\", \"filter_content_lucas\"], encoding=\"utf-8\")\n",
    "    result_wrong_pd.to_csv(output_file,mode=\"a\", index=None,header=False)\n",
    "    del result_wrong_pd #lucas 释放变量占用的内存\n",
    "    return\n",
    "\n",
    "\n",
    "# lucas\n",
    "# 读取处理完html并加上标点符号的csv文件，将其中第四列-含标点的结果进行汇总\n",
    "def huizong_yixuan_wrong(input_file,output_file):\n",
    "    result_wrong_pd = pd.read_csv(input_file,\n",
    "                                  header=0,\n",
    "                                  usecols=[\"id\", \"purchaser_new\",\"supplier_new\"], encoding=\"utf-8\")\n",
    "    result_wrong_pd.to_csv(output_file,mode=\"a\", index=None,header=False)\n",
    "    del result_wrong_pd #lucas 释放变量占用的内存\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "#@author lucas\n",
    "#@function 完成清洗完html的文件读取形成一个总体的文件\n",
    "def huizong_html_format_main(file_path,save_path):\n",
    "    path_list = os.listdir(file_path)\n",
    "    for i, folder in enumerate(path_list):\n",
    "        # for i,path in enumerate(path_list[4:]):  #当程序出现错误时，修改n，从错误的地方再开始运行,n可根据记录的i值获得。\n",
    "        folder_list = os.listdir(file_path + '/'+ folder)\n",
    "        for i, file in enumerate(folder_list):\n",
    "            if os.path.isfile(file_path + '/'+folder+'/'+ file):  # 判断是否为文件\n",
    "                cur_file_path = file_path + '/'+folder+'/'+ file\n",
    "                huizong_html_format(cur_file_path, save_path)\n",
    "\n",
    "#@author lucas 20200922\n",
    "#@function 完成对艺轩所有wrong文件中采购商为空的id数据进行汇总\n",
    "def huizong_yixuan_wrong_main(file_path,save_path):\n",
    "    path_list = os.listdir(file_path)\n",
    "    for i, folder in enumerate(path_list):\n",
    "        # for i,path in enumerate(path_list[4:]):  #当程序出现错误时，修改n，从错误的地方再开始运行,n可根据记录的i值获得。\n",
    "        folder_list = os.listdir(file_path + '/'+ folder)\n",
    "        for i, file in enumerate(folder_list):\n",
    "            if os.path.isfile(file_path + '/'+folder+'/'+ file):  # 判断是否为文件\n",
    "                cur_file_path = file_path + '/'+folder+'/'+ file\n",
    "                huizong_yixuan_wrong(cur_file_path, save_path)\n",
    "\n",
    "\n",
    "\n",
    "#@author lucas 20200922\n",
    "#@function 完成对艺轩所有wrong文件中采购商为空的id读取后，到处理完的所有id和加上标点的content中对应content进行输出汇总需要进行\n",
    "def filter_yixuan_caigoushang_wrong_content_main(yixuan_wrong_file, all_content_file, save_path):\n",
    "    #lucas 以第一列为id索引读取所有含有标点的content内容\n",
    "    all_content_dic = pd.read_csv(all_content_file, index_col=0, names=[\"id\",\"filter_content_lucas\"])\n",
    "    all_content_dic = all_content_dic.drop_duplicates(keep=\"first\")\n",
    "    all_id = all_content_dic.index\n",
    "\n",
    "    #lucas 读取艺轩那边汇总完的所有的wrong数据id\n",
    "    all_yixuan_wrong_dic = pd.read_csv(yixuan_wrong_file, index_col=0, names=[\"id\", \"purchaser_new\", \"supplier_new\"])\n",
    "    save_yixuan_wrong_content = pd.DataFrame(columns=[\"id\",\"filter_content_lucas\"])\n",
    "    for index, row in all_yixuan_wrong_dic.iterrows():\n",
    "        if row[\"purchaser_new\"] is pd.np.nan:\n",
    "            if index in all_id:\n",
    "                cur_content = all_content_dic.loc[index,\"filter_content_lucas\"]\n",
    "                # save_yixuan_wrong_content.append([{\"id\":index,\"filter_content_lucas\":cur_content}],ignore_index=True)\n",
    "                save_yixuan_wrong_content.loc[index]=[index,cur_content]\n",
    "    save_yixuan_wrong_content.to_csv(save_path, mode=\"a\", index=False, header=True)\n",
    "\n",
    "\n",
    "\n",
    "#@lucas 20200917\n",
    "#@fuction 主要先遍历服务器上文件夹下面所有文件，然后去除html格式\n",
    "def clean_html_format_main(file_path,save_path):\n",
    "    path_list = os.listdir(file_path)\n",
    "    for i, folder in enumerate(path_list):\n",
    "        # for i,path in enumerate(path_list[4:]):  #当程序出现错误时，修改n，从错误的地方再开始运行,n可根据记录的i值获得。\n",
    "        folder_list = os.listdir(file_path + '/'+ folder)\n",
    "        for i, file in enumerate(folder_list):\n",
    "            if os.path.isfile(file_path + '/'+folder+'/'+ file):  # 判断是否为文件\n",
    "                cur_file_path = file_path + '/'+folder+'/'+ file\n",
    "                clean_html_format(cur_file_path, save_path+ '/'+folder+'/'+ file)\n",
    "\n",
    "#@lucas 20200917\n",
    "#@fuction 将服务器上运行完的清洗html格式的结果进行汇总\n",
    "def clean_html_format_huizong(file_path,save_path):\n",
    "    path_list = os.listdir(file_path)\n",
    "    for i, folder in enumerate(path_list):\n",
    "        # for i,path in enumerate(path_list[4:]):  #当程序出现错误时，修改n，从错误的地方再开始运行,n可根据记录的i值获得。\n",
    "        folder_list = os.listdir(file_path + '/'+ folder)\n",
    "        for i, file in enumerate(folder_list):\n",
    "            if os.path.isfile(file_path + '/'+folder+'/'+ file):  # 判断是否为文件\n",
    "                cur_file_path = file_path + '/'+folder+'/'+ file\n",
    "                clean_html_format(cur_file_path, save_path+ '/')\n",
    "\n",
    "#@author 卢克治\n",
    "#@function 飞跃他们原始的清洗函数\n",
    "def clean_content(content):  # 预清洗中标公告，将元素放在一个数组列表里\n",
    "    sub_list = [\"<u>\", \"&nbsp;\", \"</u>\", \"<span lang=EN-US>\", \"</span>\", \"<span>\", \"\\u3000\", \"<b>\", \"</b>\", \"<strong>\",\n",
    "                \"</strong>\", \"</font>\", \"</FONT>\", \"<label>\", \"</label>\", \"</a>\"]\n",
    "    # 去除标签<u>、空格、&nbsp;、特定标签\n",
    "    for sub in sub_list:\n",
    "        content = content.replace(sub, \"\")\n",
    "    content = re.sub(r'\\<span.*?\\>', \"\", content)\n",
    "    content = re.sub(r'\\<font.*?\\>', \"\", content)\n",
    "    content = re.sub(r'\\<FONT.*?\\>', \"\", content)\n",
    "    content = re.sub(r'\\<a.*?\\>', \"\", content)\n",
    "\n",
    "    content = content.encode('gbk', 'ignore').decode('gbk', 'ignore').encode('utf8', 'ignore').decode('utf8',\n",
    "                                                                                                      'ignore')  # 去除一些特殊的符号\n",
    "    ss = re.sub('<[^>]+>', '#', content)\n",
    "    clean_content = ss.split(\"#\")  # 去除<>包含的内容\n",
    "    clean_content = [i.replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\t\", \" \") for i in clean_content]  # 去除换行和tab\n",
    "    clean_content = [re.sub(r'[@a-zA-Z0-9-\\.：; \\t]{3,}\\{.*?\\}', '', i) for i in clean_content]  # 去除CSS格式\n",
    "    clean_content = [i.strip() for i in clean_content]\n",
    "    clean_content = [i.replace(\" \", \"\") for i in clean_content if i != \"\"]\n",
    "    clean_content = [i for i in clean_content if i != \"\"]\n",
    "    clean_content = [i.replace(\":\", \"：\") for i in clean_content]\n",
    "    clean_content = [i.replace(\"？\", \"\") for i in clean_content]\n",
    "    return clean_content\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # func1\n",
    "    #----------------------完成服务器172.20.47.51下extractbids中文件的html格式清洗-------------------------\n",
    "    # lucas 先读取文件,遍历双层文件夹\n",
    "    # file_path = \"/data/nfs/extractbids\"  # 原始中标数据文件夹路径\n",
    "    # save_path = \"outputData/html_clean_lucas\"  # 存放提取出中标信息的文件夹(/data/nfs/lucas/数据清洗/outputData/html_clean_lucas)\n",
    "    # clean_html_format_main(file_path, save_path)    # lucas 0917 调用html去除格式主函数\n",
    "\n",
    "    # func2\n",
    "    # ----------------------完成服务器172.20.47.51下/data/nfs/lucas/数据清洗/outputData/html_clean_lucas清洗了html结果进行结果汇总到一个csv文件-------------------------\n",
    "    # file_path = \"/data/nfs/lucas/数据清洗/outputData/html_clean_lucas\"  # 清洗完的数据文件夹\n",
    "    # save_path = \"/data/nfs/lucas/数据清洗/outputData/html_clean_lucas结果汇总.csv\"  # 汇总的文件夹路径\n",
    "    # # lucas先输出标题，再进行内容的输出\n",
    "    # title = pd.DataFrame([\"id\",\"filter_content_lucas\"]).T\n",
    "    # title.to_csv(save_path, mode=\"a\", index=None, header=False)\n",
    "    # huizong_html_format_main(file_path, save_path)\n",
    "\n",
    "    #func3\n",
    "    # ----------------------完成服务器10.10.5.121下/data/yixuan/identify_clean_data_wrong进行结果汇总到一个csv文件-------------------------\n",
    "    # file_path = \"/data/yixuan/identify_clean_data_wrong\"  # 清洗完的数据文件夹\n",
    "    # save_path = \"/data/lucas/汇总艺轩的wrong数据/yixuan_wrong.csv\"  # 汇总的文件夹路径\n",
    "    # # lucas先输出标题，再进行内容的输出\n",
    "    # title = pd.DataFrame([\"id\", \"purchaser_new\",\"supplier_new\"]).T\n",
    "    # title.to_csv(save_path, mode=\"a\", index=None, header=False)\n",
    "    # huizong_yixuan_wrong_main(file_path, save_path)\n",
    "\n",
    "    # func4\n",
    "    # ----------------------完成服务器10.10.5.121下/data/lucas/汇总艺轩的wrong数据/yixuan_wrong结果汇总.csv中提取艺轩处理的wrong数据-------------------------\n",
    "    input_wrong_file = \"/data/lucas/汇总艺轩的wrong数据/yixuan_wrong结果汇总.csv\"\n",
    "    input_content_file = \"/data/lucas/汇总艺轩的wrong数据/input/html_clean_lucas结果汇总.csv\"\n",
    "    output_file = \"/data/lucas/汇总艺轩的wrong数据/output/yixuan_wrong采购方为空原文汇总.csv\"\n",
    "    # lucas先输出标题，再进行内容的输出\n",
    "    # title = pd.DataFrame([\"id\", \"filter_content_lucas\"]).T\n",
    "    # title.to_csv(output_file, mode=\"a\", index=None, header=False)\n",
    "    filter_yixuan_caigoushang_wrong_content_main(input_wrong_file,input_content_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
